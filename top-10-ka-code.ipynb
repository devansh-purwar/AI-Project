{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec812f3f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:00.833711Z",
     "iopub.status.busy": "2022-11-17T16:35:00.833178Z",
     "iopub.status.idle": "2022-11-17T16:35:00.855649Z",
     "shell.execute_reply": "2022-11-17T16:35:00.854685Z"
    },
    "papermill": {
     "duration": 0.033771,
     "end_time": "2022-11-17T16:35:00.858010",
     "exception": false,
     "start_time": "2022-11-17T16:35:00.824239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/emoji-prediction-1/val_set_processed.csv\n",
      "/kaggle/input/emoji-prediction-1/train_set_processed.csv\n",
      "/kaggle/input/emoji-prediction-1/test_set_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b780241a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:00.872318Z",
     "iopub.status.busy": "2022-11-17T16:35:00.871392Z",
     "iopub.status.idle": "2022-11-17T16:35:07.012055Z",
     "shell.execute_reply": "2022-11-17T16:35:07.011054Z"
    },
    "papermill": {
     "duration": 6.150559,
     "end_time": "2022-11-17T16:35:07.014889",
     "exception": false,
     "start_time": "2022-11-17T16:35:00.864330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import getopt\n",
    "import logging\n",
    "#import nltk\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, SimpleRNN\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ff635c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:07.029917Z",
     "iopub.status.busy": "2022-11-17T16:35:07.029355Z",
     "iopub.status.idle": "2022-11-17T16:35:07.552902Z",
     "shell.execute_reply": "2022-11-17T16:35:07.551883Z"
    },
    "papermill": {
     "duration": 0.533427,
     "end_time": "2022-11-17T16:35:07.555333",
     "exception": false,
     "start_time": "2022-11-17T16:35:07.021906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_proc = pd.read_csv('../input/emoji-prediction-1/train_set_processed.csv')\n",
    "val_proc = pd.read_csv('../input/emoji-prediction-1/val_set_processed.csv')\n",
    "test_proc = pd.read_csv('../input/emoji-prediction-1/test_set_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd8bc89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:07.571010Z",
     "iopub.status.busy": "2022-11-17T16:35:07.569947Z",
     "iopub.status.idle": "2022-11-17T16:35:07.577761Z",
     "shell.execute_reply": "2022-11-17T16:35:07.576840Z"
    },
    "papermill": {
     "duration": 0.017459,
     "end_time": "2022-11-17T16:35:07.579817",
     "exception": false,
     "start_time": "2022-11-17T16:35:07.562358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def emoji_to_int(labels: list):\n",
    "    return [emoji_map[emoji] for emoji in labels]\n",
    "\n",
    "\n",
    "def keep_top_10(data, top_10: list): \n",
    "    \"\"\"\n",
    "    Function that checks, whether Tweet consists of one of the top ten emojis.\n",
    "    If, and only if, Tweet consists one of the most frequent emojis, \n",
    "    Tweet will be used for further analysis.\n",
    "    Else: Line will be dropped.\n",
    "    \"\"\"\n",
    "    idx_drop = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row[1] not in top_10:\n",
    "            idx_drop.append(index)\n",
    "    return data.drop(data.index[idx_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ea4005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:07.593762Z",
     "iopub.status.busy": "2022-11-17T16:35:07.593463Z",
     "iopub.status.idle": "2022-11-17T16:35:07.609037Z",
     "shell.execute_reply": "2022-11-17T16:35:07.608122Z"
    },
    "papermill": {
     "duration": 0.024984,
     "end_time": "2022-11-17T16:35:07.611104",
     "exception": false,
     "start_time": "2022-11-17T16:35:07.586120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ğŸ˜', 'ğŸ˜‚', 'â¤ï¸', 'ğŸ’•', 'ğŸ˜Š', 'ğŸ˜˜', 'ğŸ˜­', 'ğŸ’–', 'ğŸ˜', 'âœ¨']\n"
     ]
    }
   ],
   "source": [
    "top_10_test = test_proc['label'].value_counts()[:10].index.to_list()\n",
    "print(top_10_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d1f494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:07.626604Z",
     "iopub.status.busy": "2022-11-17T16:35:07.626171Z",
     "iopub.status.idle": "2022-11-17T16:35:07.631213Z",
     "shell.execute_reply": "2022-11-17T16:35:07.630105Z"
    },
    "papermill": {
     "duration": 0.015077,
     "end_time": "2022-11-17T16:35:07.633678",
     "exception": false,
     "start_time": "2022-11-17T16:35:07.618601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emoji_map = {emoji: i for i, emoji in enumerate(top_10_test)}\n",
    "idx_emoji = {i: emoji for i, emoji in enumerate(top_10_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63047822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:07.648119Z",
     "iopub.status.busy": "2022-11-17T16:35:07.647777Z",
     "iopub.status.idle": "2022-11-17T16:35:19.706433Z",
     "shell.execute_reply": "2022-11-17T16:35:19.705287Z"
    },
    "papermill": {
     "duration": 12.069166,
     "end_time": "2022-11-17T16:35:19.709617",
     "exception": false,
     "start_time": "2022-11-17T16:35:07.640451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets in the train data set: 81236\n",
      "Number of Tweets in the test data set: 7646\n",
      "Number of Tweets in the validation data set: 7613\n"
     ]
    }
   ],
   "source": [
    "train_data = keep_top_10(train_proc, top_10_test)\n",
    "print(\"Number of Tweets in the train data set: {}\".format(len(train_data)))\n",
    "test_data = keep_top_10(test_proc, top_10_test)\n",
    "print(\"Number of Tweets in the test data set: {}\".format(len(test_data)))\n",
    "val_data = keep_top_10(val_proc, top_10_test)\n",
    "print(\"Number of Tweets in the validation data set: {}\".format(len(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34af0002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:19.726223Z",
     "iopub.status.busy": "2022-11-17T16:35:19.725617Z",
     "iopub.status.idle": "2022-11-17T16:35:19.744134Z",
     "shell.execute_reply": "2022-11-17T16:35:19.743284Z"
    },
    "papermill": {
     "duration": 0.028577,
     "end_time": "2022-11-17T16:35:19.746124",
     "exception": false,
     "start_time": "2022-11-17T16:35:19.717547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tweets_cleaning(tweets, labels, use_stopwords = False, train = False, use_bigrams = False, \n",
    "                    lowercase = True, stemming = False, min_df = 2, embedding = False):\n",
    "    \"\"\"\n",
    "    Text cleaning function that performs all necessary text preprocessing steps.\n",
    "    Function only keeps characters, that are alphanumerical (non-alphanumerical values are discarded).\n",
    "    Digits are treated by regular expressions.\n",
    "    Lower-casing is performed to reduce noise and normalize the text (convert it into a uniform representation).\n",
    "    Stemming is performed to only keep the stem of each word token but not any other deviated form. \n",
    "    Stop words (i.e., words that occur more frequently than other words in a given corpus) are removed.\n",
    "    \"\"\"\n",
    "    if stemming:\n",
    "        # initialize Lancaster stemmer\n",
    "        st = LancasterStemmer()\n",
    "    if use_stopwords:\n",
    "        # create list of stopwords\n",
    "        stopwords = list(set(stopwords.words('english')))\n",
    "    cleaned_data = []\n",
    "    cleaned_labels = []\n",
    "    \n",
    "    all_bigrams = [] # serves as place-holder\n",
    "    bigrams_dict = dict()\n",
    "    vocab = dict()\n",
    "    \n",
    "    for tweet, label in zip(tweets, labels):\n",
    "        tweet = re.sub(r'&amp\\S+','', tweet)\n",
    "        tweet = re.sub(r' & ', ' and ', tweet)\n",
    "        tweet = re.sub(r'!+', ' ! ', tweet)\n",
    "        tweet = re.sub(r'[?]+', ' ? ', tweet)\n",
    "        tweet = re.sub('@.+', '@user', tweet)\n",
    "        tweet = re.sub('#', '# ', tweet)\n",
    "\n",
    "        # Create spaces instead of some punctuation marks, but not if it's part of an emoticon\n",
    "        tweet = ' '.join([word if re.search(r'(?:X|:|;|=)(?:-)?(?:\\)|\\(|O|D|P|S)+', word)\n",
    "            else re.sub('[,.;\\-_:/\\n\\t]+', ' ', word) for word in tweet.split()])\n",
    "        \n",
    "        tweet = tweet.split(\" \")\n",
    "        \n",
    "        cleaned_tweet = []\n",
    "        for word in tweet:\n",
    "            \n",
    "            #if emoticon is in word, keep the emoticon\n",
    "            if re.search(r'(?:X|:|;|=)(?:-)?(?:\\)|\\(|O|D|P|S)+', word):\n",
    "                cleaned_word = word\n",
    "            else:\n",
    "                # keep special characters which might carry important information\n",
    "                # perform lower-casing to normalize the text and reduce noise\n",
    "                cleaned_word = ''.join([char for char in word if re.search('[<>$#â‚¬Â£!?@=]', char) or\n",
    "                                        char.isalnum()])\n",
    "            if lowercase:\n",
    "                cleaned_word = cleaned_word.lower()\n",
    "                \n",
    "            if \"<3\" not in cleaned_word:\n",
    "                cleaned_word = re.sub('[0-9]', '0', cleaned_word)\n",
    "  \n",
    "            # removes each \\n (i.e., new line) or \\t (i.e., tab) -> pipe char denotes a disjunction\n",
    "            cleaned_word = re.sub(r'( \\n| \\t)+', '', cleaned_word)\n",
    "            \n",
    "            if stemming:\n",
    "                cleaned_word = st.stem(cleaned_word)\n",
    "            \n",
    "            if len(cleaned_word) > 0:\n",
    "                if not use_stopwords:\n",
    "                    cleaned_tweet.append(cleaned_word)\n",
    "                elif(cleaned_word not in stopwords):\n",
    "                    cleaned_tweet.append(cleaned_word)\n",
    "\n",
    "                if train:\n",
    "                    if cleaned_word in vocab:\n",
    "                        vocab[cleaned_word] += 1\n",
    "                    else:\n",
    "                        vocab[cleaned_word] = 1\n",
    "            \n",
    "        # only append tweets with more than 1 word per tweet\n",
    "        if len(cleaned_tweet) > 1:\n",
    "            \n",
    "            if train and use_bigrams:\n",
    "                \n",
    "                bigrams = [' '.join([cleaned_tweet[i-1], cleaned_tweet[i]]) \n",
    "                           for i, _ in enumerate(cleaned_tweet) if i > 0]\n",
    "                \n",
    "                for bigram in bigrams:\n",
    "                    \n",
    "                    if bigram in bigrams_dict:\n",
    "                        bigrams_dict[bigram] += 1\n",
    "                    else:\n",
    "                        bigrams_dict[bigram] = 1 \n",
    "\n",
    "            cleaned_tweet = ' '.join(cleaned_tweet)\n",
    "            cleaned_data.append(cleaned_tweet)\n",
    "            cleaned_labels.append(label)\n",
    "            \n",
    "    if train and embedding and not use_bigrams:\n",
    "        \n",
    "        word2index = dict()\n",
    "        i = 1\n",
    "        for word in vocab.keys():\n",
    "            word2index[word] = i\n",
    "            i += 1\n",
    "            \n",
    "        word2index.update({'UNK': len(word2idx) + 1})\n",
    "        \n",
    "        assert len(cleaned_data) == len(cleaned_labels)\n",
    "\n",
    "        return cleaned_data, cleaned_labels, word2index\n",
    "                \n",
    "    if train:\n",
    "        vocab = [word for word, freq in vocab.items() if freq >= min_df]  \n",
    "        if use_bigrams:\n",
    "            all_bigrams = [bigram for bigram, freq in bigrams_dict.items() if freq >= min_df]\n",
    "            vocab.extend(all_bigrams)\n",
    "        \n",
    "    assert len(cleaned_data) == len(cleaned_labels)\n",
    "    \n",
    "    return cleaned_data, cleaned_labels, sorted(vocab), sorted(all_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bda71d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:19.759872Z",
     "iopub.status.busy": "2022-11-17T16:35:19.759612Z",
     "iopub.status.idle": "2022-11-17T16:35:28.346571Z",
     "shell.execute_reply": "2022-11-17T16:35:28.345508Z"
    },
    "papermill": {
     "duration": 8.59672,
     "end_time": "2022-11-17T16:35:28.349104",
     "exception": false,
     "start_time": "2022-11-17T16:35:19.752384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_data, train_labels, vocab, bigrams = tweets_cleaning(train_data.text, \n",
    "                                                                   train_data.label, \n",
    "                                                                   use_stopwords = False, \n",
    "                                                                   train = True, \n",
    "                                                                   use_bigrams = True, \n",
    "                                                                   lowercase = True,\n",
    "                                                                   min_df = 2)\n",
    "\n",
    "cleaned_test_data, test_labels, _, _ = tweets_cleaning(test_data.text, \n",
    "                                                       test_data.label, \n",
    "                                                       use_stopwords = False, \n",
    "                                                       lowercase = True)\n",
    "\n",
    "cleaned_val_data, val_labels, _, _ = tweets_cleaning(val_data.text, \n",
    "                                                     val_data.label, \n",
    "                                                     use_stopwords = False, \n",
    "                                                     lowercase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7378c6cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:28.365273Z",
     "iopub.status.busy": "2022-11-17T16:35:28.363715Z",
     "iopub.status.idle": "2022-11-17T16:35:28.371941Z",
     "shell.execute_reply": "2022-11-17T16:35:28.370944Z"
    },
    "papermill": {
     "duration": 0.017738,
     "end_time": "2022-11-17T16:35:28.373751",
     "exception": false,
     "start_time": "2022-11-17T16:35:28.356013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens in the vocabulary: 55855\n",
      "Number of Tweets per data set after text cleaning was computed:\n",
      "Train: 68750\n",
      "Test: 6539\n",
      "Validation: 6505\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique tokens in the vocabulary: {}\".format(len(vocab)))\n",
    "print(\"Number of Tweets per data set after text cleaning was computed:\")\n",
    "print(\"Train: {}\".format(len(cleaned_train_data)))\n",
    "print(\"Test: {}\".format(len(cleaned_test_data)))\n",
    "print(\"Validation: {}\".format(len(cleaned_val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d833b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:28.388330Z",
     "iopub.status.busy": "2022-11-17T16:35:28.388051Z",
     "iopub.status.idle": "2022-11-17T16:35:28.399070Z",
     "shell.execute_reply": "2022-11-17T16:35:28.398133Z"
    },
    "papermill": {
     "duration": 0.020324,
     "end_time": "2022-11-17T16:35:28.401024",
     "exception": false,
     "start_time": "2022-11-17T16:35:28.380700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = emoji_to_int(train_labels)\n",
    "y_test = emoji_to_int(test_labels)\n",
    "y_val = emoji_to_int(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f037591e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:28.415173Z",
     "iopub.status.busy": "2022-11-17T16:35:28.414900Z",
     "iopub.status.idle": "2022-11-17T16:35:28.422460Z",
     "shell.execute_reply": "2022-11-17T16:35:28.421384Z"
    },
    "papermill": {
     "duration": 0.01724,
     "end_time": "2022-11-17T16:35:28.424744",
     "exception": false,
     "start_time": "2022-11-17T16:35:28.407504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bag_of_words(train: list, test: list, val: list, ngram: tuple, vocab = None, \n",
    "                 n_best_factor = 0.7):\n",
    "    \"\"\"\n",
    "    Create a weighted bag-of-words unigram or bigram representation of provided tweets.\n",
    "    Ngram is set to unigram by default. If bigram bag-of-words should be created, pass tuple (2, 2).\n",
    "    \n",
    "    Vocabulary argument is set to None by default. \n",
    "    You can pass a vocabulary to this function, which may then be used for TfidfVectorizer. \n",
    "    If you do not pass a vocabulary to this function, TfidfVectorizer will create a vocabulary itself.\n",
    "    \"\"\" \n",
    "    \n",
    "    vectorizer = CountVectorizer(encoding = 'utf-8', ngram_range = ngram, analyzer = 'word', \n",
    "                                 vocabulary = vocab, max_df = 0.9)\n",
    "    \n",
    "    train_BoW = vectorizer.fit_transform(train) #.toarray()\n",
    "    test_BoW = vectorizer.transform(test) #.toarray()\n",
    "    val_BoW = vectorizer.transform(val) #.toarray()\n",
    "    \n",
    "\n",
    "    return train_BoW, test_BoW, val_BoW\n",
    "\n",
    "def to_cat_matrix(y):\n",
    "\n",
    "    \"\"\" \n",
    "    Binary one-hot encoding using an indicator matrix.\n",
    "    This function converts labels to a categorical matrix which is of size N x K.\n",
    "    Each row is a row vector with k-1 zeros and a single 1.\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    K = len(set(y))\n",
    "    ind_matrix = np.zeros((N,K), dtype = int)\n",
    "    \n",
    "    for i, cat in enumerate(y):\n",
    "        ind_matrix[i, int(cat)] = 1\n",
    "        \n",
    "    return ind_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c02c8499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:28.439204Z",
     "iopub.status.busy": "2022-11-17T16:35:28.438232Z",
     "iopub.status.idle": "2022-11-17T16:35:29.604437Z",
     "shell.execute_reply": "2022-11-17T16:35:29.603483Z"
    },
    "papermill": {
     "duration": 1.176062,
     "end_time": "2022-11-17T16:35:29.607075",
     "exception": false,
     "start_time": "2022-11-17T16:35:28.431013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_val = bag_of_words(cleaned_train_data, cleaned_test_data, cleaned_val_data, ngram = (1, 2), vocab = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "433e142b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:29.621719Z",
     "iopub.status.busy": "2022-11-17T16:35:29.621361Z",
     "iopub.status.idle": "2022-11-17T16:35:29.639117Z",
     "shell.execute_reply": "2022-11-17T16:35:29.638151Z"
    },
    "papermill": {
     "duration": 0.027034,
     "end_time": "2022-11-17T16:35:29.640951",
     "exception": false,
     "start_time": "2022-11-17T16:35:29.613917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = emoji_to_int(train_data.iloc[:68750,:].label)\n",
    "y_test = emoji_to_int(test_data.iloc[:6539,:].label)\n",
    "y_val = emoji_to_int(val_data.iloc[:6505,:].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23dc54cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:29.656101Z",
     "iopub.status.busy": "2022-11-17T16:35:29.654583Z",
     "iopub.status.idle": "2022-11-17T16:35:31.856950Z",
     "shell.execute_reply": "2022-11-17T16:35:31.855529Z"
    },
    "papermill": {
     "duration": 2.212406,
     "end_time": "2022-11-17T16:35:31.859715",
     "exception": false,
     "start_time": "2022-11-17T16:35:29.647309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_val = bag_of_words(train_data.iloc[:68750,:].text, test_data.iloc[:6539,:].text, val_data.iloc[:6505,:].text, ngram = (1, 2), vocab= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27bc4b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:31.890993Z",
     "iopub.status.busy": "2022-11-17T16:35:31.890434Z",
     "iopub.status.idle": "2022-11-17T16:35:31.906866Z",
     "shell.execute_reply": "2022-11-17T16:35:31.906005Z"
    },
    "papermill": {
     "duration": 0.041009,
     "end_time": "2022-11-17T16:35:31.914163",
     "exception": false,
     "start_time": "2022-11-17T16:35:31.873154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68750, 268399)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4844db52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:31.935037Z",
     "iopub.status.busy": "2022-11-17T16:35:31.934593Z",
     "iopub.status.idle": "2022-11-17T16:35:31.946865Z",
     "shell.execute_reply": "2022-11-17T16:35:31.946095Z"
    },
    "papermill": {
     "duration": 0.025572,
     "end_time": "2022-11-17T16:35:31.949573",
     "exception": false,
     "start_time": "2022-11-17T16:35:31.924001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(hidden_units: int, input_dims: int, n_labels: int):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim = input_dims, activation = 'relu'))\n",
    "    model.add(Dropout(0.5)) # dropout is important to prevent model from overfitting\n",
    "    model.add(Dense(n_labels, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def preds_to_labels(ypred):\n",
    "    \"\"\"\n",
    "    Firstly, extract the predicted label from a vector of probability distributions.\n",
    "    Secondly, retrieve index of highest value (i.e., highest probability).\n",
    "    \"\"\"\n",
    "    num_labels = [np.argmax(pred) for pred in ypred]\n",
    "    return np.array(num_labels)\n",
    "\n",
    "def accuracy_top_n(y_true, y_preds, top_n = 3):\n",
    "    \"\"\"\n",
    "    If the correct label / emoji is among the top n (e.g., two, three) predictions,\n",
    "    we consider the prediction as correctly labeled.\n",
    "    \"\"\"\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    \n",
    "    for i, pred in enumerate(y_preds):\n",
    "        top_3 = np.argsort(pred)[-top_n:]\n",
    "        if y_true[i] in top_3:\n",
    "            n_correct += 1\n",
    "        n_total += 1\n",
    "        \n",
    "    ratio = n_correct / n_total\n",
    "    return round(ratio, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0232b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:31.969745Z",
     "iopub.status.busy": "2022-11-17T16:35:31.969426Z",
     "iopub.status.idle": "2022-11-17T16:35:32.016254Z",
     "shell.execute_reply": "2022-11-17T16:35:32.015490Z"
    },
    "papermill": {
     "duration": 0.059677,
     "end_time": "2022-11-17T16:35:32.018736",
     "exception": false,
     "start_time": "2022-11-17T16:35:31.959059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get indicator matrix with one-hot-encoded vectors per label (of all labels)\n",
    "y_train = to_cat_matrix(y_train)\n",
    "y_val = to_cat_matrix(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68ed9f51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:32.039449Z",
     "iopub.status.busy": "2022-11-17T16:35:32.039144Z",
     "iopub.status.idle": "2022-11-17T16:35:32.080288Z",
     "shell.execute_reply": "2022-11-17T16:35:32.079531Z"
    },
    "papermill": {
     "duration": 0.054238,
     "end_time": "2022-11-17T16:35:32.082830",
     "exception": false,
     "start_time": "2022-11-17T16:35:32.028592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.sort_indices()\n",
    "X_val.sort_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e862879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:32.103535Z",
     "iopub.status.busy": "2022-11-17T16:35:32.103166Z",
     "iopub.status.idle": "2022-11-17T16:35:34.927970Z",
     "shell.execute_reply": "2022-11-17T16:35:34.926968Z"
    },
    "papermill": {
     "duration": 2.837896,
     "end_time": "2022-11-17T16:35:34.930704",
     "exception": false,
     "start_time": "2022-11-17T16:35:32.092808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 16:35:32.199578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:32.326062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:32.327157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:32.329037: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 16:35:32.329378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:32.330377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:32.331311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:34.516303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:34.517319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:34.518056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 16:35:34.518659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# set number of hidden units, epochs and batch size\n",
    "n_units = 60\n",
    "n_epochs = 6\n",
    "n_batches = 32\n",
    "\n",
    "model = get_model(n_units, X_train.shape[1], y_train.shape[1])\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', mode='max', verbose=1)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814d14ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:35:34.947304Z",
     "iopub.status.busy": "2022-11-17T16:35:34.946463Z",
     "iopub.status.idle": "2022-11-17T16:37:22.516432Z",
     "shell.execute_reply": "2022-11-17T16:37:22.514712Z"
    },
    "papermill": {
     "duration": 107.580884,
     "end_time": "2022-11-17T16:37:22.518895",
     "exception": false,
     "start_time": "2022-11-17T16:35:34.938011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 60), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "2022-11-17 16:35:35.552816: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 17s 7ms/step - loss: 1.9328 - accuracy: 0.3489 - val_loss: 1.7531 - val_accuracy: 0.4092\n",
      "Epoch 2/6\n",
      "2149/2149 [==============================] - 16s 7ms/step - loss: 1.4179 - accuracy: 0.5251 - val_loss: 1.6504 - val_accuracy: 0.4563\n",
      "Epoch 3/6\n",
      "2149/2149 [==============================] - 15s 7ms/step - loss: 0.9339 - accuracy: 0.7006 - val_loss: 1.7029 - val_accuracy: 0.4569\n",
      "Epoch 4/6\n",
      "2149/2149 [==============================] - 15s 7ms/step - loss: 0.6344 - accuracy: 0.8027 - val_loss: 1.8351 - val_accuracy: 0.4589\n",
      "Epoch 5/6\n",
      "2149/2149 [==============================] - 15s 7ms/step - loss: 0.4723 - accuracy: 0.8544 - val_loss: 1.9827 - val_accuracy: 0.4575\n",
      "Epoch 6/6\n",
      "2149/2149 [==============================] - 15s 7ms/step - loss: 0.3817 - accuracy: 0.8806 - val_loss: 2.1258 - val_accuracy: 0.4478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7785e51dd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = n_epochs, \n",
    "          batch_size = n_batches, callbacks = [es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e95ab62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:37:22.710332Z",
     "iopub.status.busy": "2022-11-17T16:37:22.709309Z",
     "iopub.status.idle": "2022-11-17T16:37:24.405319Z",
     "shell.execute_reply": "2022-11-17T16:37:24.404244Z"
    },
    "papermill": {
     "duration": 1.79324,
     "end_time": "2022-11-17T16:37:24.408072",
     "exception": false,
     "start_time": "2022-11-17T16:37:22.614832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load best model\n",
    "model.save('best_model.h5')\n",
    "saved_model = load_model('best_model.h5')\n",
    "# get predictions\n",
    "y_pred_test = saved_model.predict(X_test)\n",
    "# convert predictions to labels\n",
    "y_pred_labels = preds_to_labels(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01ea30dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:37:24.602514Z",
     "iopub.status.busy": "2022-11-17T16:37:24.602123Z",
     "iopub.status.idle": "2022-11-17T16:37:24.731716Z",
     "shell.execute_reply": "2022-11-17T16:37:24.729858Z"
    },
    "papermill": {
     "duration": 0.231066,
     "end_time": "2022-11-17T16:37:24.734363",
     "exception": false,
     "start_time": "2022-11-17T16:37:24.503297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6908\n",
      "0.5958\n",
      "0.454\n"
     ]
    }
   ],
   "source": [
    "# if true label is among the top 3 predictions, prediction is deemed correctly labeled\n",
    "print(accuracy_top_n(y_test, y_pred_test, top_n = 3))\n",
    "# if true label is among the top 2 predictions, prediction is deemed correctly labeled\n",
    "print(accuracy_top_n(y_test, y_pred_test, top_n = 2))\n",
    "# if true label is among the top 1 prediction, prediction is deemed correctly labeled\n",
    "print(accuracy_top_n(y_test, y_pred_test, top_n = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d19cd850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:37:24.926572Z",
     "iopub.status.busy": "2022-11-17T16:37:24.925627Z",
     "iopub.status.idle": "2022-11-17T16:37:24.930324Z",
     "shell.execute_reply": "2022-11-17T16:37:24.929384Z"
    },
    "papermill": {
     "duration": 0.10232,
     "end_time": "2022-11-17T16:37:24.932563",
     "exception": false,
     "start_time": "2022-11-17T16:37:24.830243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f1_score(y_test, y_pred_labels, average = 'weighted')\n",
    "# f1_score(y_test, y_pred_labels, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76391463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:37:25.124187Z",
     "iopub.status.busy": "2022-11-17T16:37:25.123839Z",
     "iopub.status.idle": "2022-11-17T16:37:25.147008Z",
     "shell.execute_reply": "2022-11-17T16:37:25.145724Z"
    },
    "papermill": {
     "duration": 0.125164,
     "end_time": "2022-11-17T16:37:25.151060",
     "exception": false,
     "start_time": "2022-11-17T16:37:25.025896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           ğŸ˜       0.48      0.59      0.53      1353\n",
      "           ğŸ˜‚       0.55      0.64      0.59      1233\n",
      "          â¤ï¸       0.42      0.49      0.45      1151\n",
      "           ğŸ’•       0.34      0.31      0.33       635\n",
      "           ğŸ˜Š       0.39      0.29      0.33       585\n",
      "           ğŸ˜˜       0.47      0.26      0.33       331\n",
      "           ğŸ˜­       0.37      0.28      0.32       333\n",
      "           ğŸ’–       0.41      0.22      0.29       316\n",
      "           ğŸ˜       0.41      0.31      0.35       306\n",
      "           âœ¨       0.45      0.38      0.41       296\n",
      "\n",
      "    accuracy                           0.45      6539\n",
      "   macro avg       0.43      0.38      0.39      6539\n",
      "weighted avg       0.45      0.45      0.44      6539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_labels, target_names=top_10_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4224a3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:37:25.345905Z",
     "iopub.status.busy": "2022-11-17T16:37:25.345094Z",
     "iopub.status.idle": "2022-11-17T16:37:25.356159Z",
     "shell.execute_reply": "2022-11-17T16:37:25.355299Z"
    },
    "papermill": {
     "duration": 0.107958,
     "end_time": "2022-11-17T16:37:25.358172",
     "exception": false,
     "start_time": "2022-11-17T16:37:25.250214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = emoji_to_int(train_labels)\n",
    "y_test = emoji_to_int(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be9efe40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:37:25.554425Z",
     "iopub.status.busy": "2022-11-17T16:37:25.554036Z",
     "iopub.status.idle": "2022-11-17T16:37:25.565969Z",
     "shell.execute_reply": "2022-11-17T16:37:25.564967Z"
    },
    "papermill": {
     "duration": 0.118185,
     "end_time": "2022-11-17T16:37:25.573953",
     "exception": false,
     "start_time": "2022-11-17T16:37:25.455768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely evening w @user\n",
      "true label: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜˜\n",
      "prediction: ğŸ˜‚\n",
      "\n",
      "the shit @user\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜‚\n",
      "\n",
      "i want swole but i enjoyed both\n",
      "true label: ğŸ’•\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ˜Š\n",
      "prediction: ğŸ˜˜\n",
      "\n",
      "vibinn till i fall asleep ily lil yachty\n",
      "true label: â¤ï¸\n",
      "prediction: ğŸ˜‚\n",
      "prediction: âœ¨\n",
      "prediction: ğŸ˜˜\n",
      "\n",
      "final preparation for our # yearofmercy # interfaith event tomorrow ! # badges\n",
      "true label: ğŸ’•\n",
      "prediction: ğŸ˜Š\n",
      "prediction: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "\n",
      "what do you call a fish with no eyes ? fsh !\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜­\n",
      "\n",
      "when hes extra sweet to you but you use to dogs so you dont know how to accept him being sweet\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜˜\n",
      "prediction: â¤ï¸\n",
      "\n",
      "tagged by @user well\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "\n",
      "endlessly and untiringly falling for your dimples\n",
      "true label: ğŸ˜\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜­\n",
      "prediction: ğŸ˜\n",
      "\n",
      "00 months with this beautiful girl i love you sky\n",
      "true label: â¤ï¸\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜Š\n",
      "prediction: ğŸ˜‚\n",
      "\n",
      "me and bae @user\n",
      "true label: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ’–\n",
      "\n",
      "my sister\n",
      "true label: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜\n",
      "\n",
      "my new babies\n",
      "true label: ğŸ˜\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜­\n",
      "prediction: ğŸ˜Š\n",
      "\n",
      "0 year and 0 months with this qt\n",
      "true label: ğŸ’•\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜­\n",
      "\n",
      "relationship goals\n",
      "true label: ğŸ’–\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "\n",
      "# 0yearswithbts one of the best decision i made in my life\n",
      "true label: âœ¨\n",
      "prediction: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "prediction: âœ¨\n",
      "\n",
      "this looks so good\n",
      "true label: ğŸ˜\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜‚\n",
      "prediction: â¤ï¸\n",
      "\n",
      "how did we get from here to here\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜˜\n",
      "\n",
      "adorkable the combination of adorable and dork being very cute\n",
      "true label: ğŸ˜\n",
      "prediction: âœ¨\n",
      "prediction: ğŸ’•\n",
      "prediction: â¤ï¸\n",
      "\n",
      "please help out with anything you can ! keep them in your prayers !\n",
      "true label: ğŸ’–\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜­\n",
      "\n",
      "omg this is precious\n",
      "true label: ğŸ’–\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜Š\n",
      "\n",
      "feels surreal to finally be at a @user\n",
      "true label: âœ¨\n",
      "prediction: âœ¨\n",
      "prediction: ğŸ’–\n",
      "prediction: ğŸ’•\n",
      "\n",
      "im not a makeup artist this prob looks terrible to you but im proud of myself\n",
      "true label: âœ¨\n",
      "prediction: âœ¨\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜Š\n",
      "\n",
      "pics @user\n",
      "true label: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜Š\n",
      "\n",
      "this is jordy and he now has my entire heart\n",
      "true label: â¤ï¸\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ’•\n",
      "\n",
      "sungyeol is really a nice piece of art\n",
      "true label: ğŸ’•\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜Š\n",
      "prediction: ğŸ˜­\n",
      "\n",
      "my @user\n",
      "true label: ğŸ˜\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜Š\n",
      "prediction: ğŸ˜˜\n",
      "\n",
      "jk they lied to me 0 0\n",
      "true label: â¤ï¸\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "prediction: âœ¨\n",
      "\n",
      "good morning\n",
      "true label: ğŸ˜\n",
      "prediction: ğŸ˜˜\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "\n",
      "yongguk is in charge of giving nicknames to the members everytime they celebrate their birthdays\n",
      "true label: ğŸ˜‚\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "\n",
      "shoutout to my 0000 self\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜­\n",
      "\n",
      "and was dreaming at times\n",
      "true label: ğŸ˜\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ’•\n",
      "prediction: â¤ï¸\n",
      "\n",
      "when he drew a rose for armys\n",
      "true label: â¤ï¸\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "\n",
      "sometimes you just need to drive to st george for fro yo\n",
      "true label: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ˜‚\n",
      "\n",
      "m are bae\n",
      "true label: ğŸ˜\n",
      "prediction: âœ¨\n",
      "prediction: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "\n",
      "theres always that one friend that doesnt want to be there\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜­\n",
      "prediction: ğŸ˜‚\n",
      "\n",
      "flash ali modu sheriff finally gains entrance into pdp headquarters and assumes position as chairman\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜‚\n",
      "prediction: âœ¨\n",
      "prediction: â¤ï¸\n",
      "\n",
      "what the tut\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ˜Š\n",
      "\n",
      "cant find my category so we gone try this # carefreetwitter # blackgirltwitter\n",
      "true label: âœ¨\n",
      "prediction: ğŸ’–\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ’•\n",
      "\n",
      "what happens when youre friends with romeo\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜‚\n",
      "prediction: ğŸ˜­\n",
      "\n",
      "queen mera crown is sickkkk !\n",
      "true label: ğŸ˜\n",
      "prediction: ğŸ˜­\n",
      "prediction: ğŸ˜‚\n",
      "prediction: â¤ï¸\n",
      "\n",
      "happy fathers day chris\n",
      "true label: ğŸ’•\n",
      "prediction: ğŸ˜˜\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ˜Š\n",
      "\n",
      "osu camp was fun\n",
      "true label: â¤ï¸\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜Š\n",
      "prediction: â¤ï¸\n",
      "\n",
      "youre amazing greyson ! may your life be blessed dont forget to hug my pillow tonight pls hoho\n",
      "true label: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "prediction: âœ¨\n",
      "prediction: ğŸ’•\n",
      "\n",
      "sky was beautiful tonight !\n",
      "true label: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ’•\n",
      "\n",
      "aww look at my best friend holla at him @user\n",
      "true label: â¤ï¸\n",
      "prediction: ğŸ’•\n",
      "prediction: ğŸ’–\n",
      "prediction: ğŸ˜\n",
      "\n",
      "@user dream big chase them turn them into reality\n",
      "true label: ğŸ’•\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜\n",
      "prediction: â¤ï¸\n",
      "\n",
      "go and watch # versevideo by @user\n",
      "true label: ğŸ’•\n",
      "prediction: âœ¨\n",
      "prediction: ğŸ˜‚\n",
      "prediction: â¤ï¸\n",
      "\n",
      "dumo a straight savage\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ˜Š\n",
      "prediction: â¤ï¸\n",
      "\n",
      "day 0 of download done ! got soaked and thought id broke my rib in the rammstein pit but alls good\n",
      "true label: ğŸ˜‚\n",
      "prediction: ğŸ˜\n",
      "prediction: ğŸ’–\n",
      "prediction: ğŸ˜­\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out example tweets\n",
    "start = 100\n",
    "finish = 150\n",
    "for tweet, preds, true in zip(cleaned_test_data[start:finish], y_pred_test[start:finish], test_labels[start:finish]):\n",
    "    print(tweet)\n",
    "    pred = np.argsort(preds)\n",
    "    print(\"true label:\", true)\n",
    "    print(\"prediction:\", idx_emoji[pred[-1]])\n",
    "    print(\"prediction:\", idx_emoji[pred[-2]])\n",
    "    print(\"prediction:\", idx_emoji[pred[-3]])    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c3c173f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:37:25.826089Z",
     "iopub.status.busy": "2022-11-17T16:37:25.825048Z",
     "iopub.status.idle": "2022-11-17T16:37:25.836466Z",
     "shell.execute_reply": "2022-11-17T16:37:25.835145Z"
    },
    "papermill": {
     "duration": 0.169156,
     "end_time": "2022-11-17T16:37:25.839376",
     "exception": false,
     "start_time": "2022-11-17T16:37:25.670220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ğŸ’•': 586, 'â¤ï¸': 1340, 'ğŸ˜‚': 1437, 'ğŸ˜': 1657, 'ğŸ˜Š': 438, 'âœ¨': 248, 'ğŸ˜˜': 179, 'ğŸ˜­': 250, 'ğŸ˜': 234, 'ğŸ’–': 170}\n"
     ]
    }
   ],
   "source": [
    "# Count occurances of Emojis in the predictions\n",
    "freq = {}\n",
    "for pred in y_pred_labels:\n",
    "    if idx_emoji[pred] in freq:\n",
    "        freq[idx_emoji[pred]] += 1\n",
    "    else:\n",
    "        freq[idx_emoji[pred]] = 1 \n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af43295c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T16:37:26.031823Z",
     "iopub.status.busy": "2022-11-17T16:37:26.030861Z",
     "iopub.status.idle": "2022-11-17T16:37:26.039156Z",
     "shell.execute_reply": "2022-11-17T16:37:26.038084Z"
    },
    "papermill": {
     "duration": 0.105369,
     "end_time": "2022-11-17T16:37:26.042384",
     "exception": false,
     "start_time": "2022-11-17T16:37:25.937015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'âœ¨': 326, 'ğŸ˜Š': 519, 'â¤ï¸': 1193, 'ğŸ˜': 307, 'ğŸ˜­': 343, 'ğŸ˜‚': 1194, 'ğŸ˜': 1367, 'ğŸ’•': 650, 'ğŸ˜˜': 326, 'ğŸ’–': 314}\n"
     ]
    }
   ],
   "source": [
    "# Count occurances of Emojis in the test set\n",
    "freq = {}\n",
    "for y_true in y_test:\n",
    "    if idx_emoji[y_true] in freq:\n",
    "        freq[idx_emoji[y_true]] += 1\n",
    "    else:\n",
    "        freq[idx_emoji[y_true]] = 1 \n",
    "print(freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 156.461635,
   "end_time": "2022-11-17T16:37:29.450726",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-17T16:34:52.989091",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
