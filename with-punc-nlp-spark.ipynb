{"metadata":{"colab":{"name":"bert-sentence-embeddings.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n# Install java\n! apt-get update -qq\n! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n! java -version\n\n# Install pyspark\n! pip install --ignore-installed -q pyspark==2.4.4\n! pip install --ignore-installed -q spark-nlp==2.7.1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30C6sdTtwjex","outputId":"7df5c56b-dc8d-4656-a8d3-04496d3a3ece","execution":{"iopub.status.busy":"2022-11-12T15:21:51.584323Z","iopub.execute_input":"2022-11-12T15:21:51.584768Z","iopub.status.idle":"2022-11-12T15:23:02.535155Z","shell.execute_reply.started":"2022-11-12T15:21:51.584678Z","shell.execute_reply":"2022-11-12T15:23:02.533982Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"openjdk version \"1.8.0_352\"\nOpenJDK Runtime Environment (build 1.8.0_352-8u352-ga-1~20.04-b08)\nOpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import sparknlp\n\nspark = sparknlp.start(gpu = True) # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\nfrom pyspark.ml import Pipeline\nimport pandas as pd\n\nprint(\"Spark NLP version\", sparknlp.version())\n\nprint(\"Apache Spark version:\", spark.version)\n\nspark","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"id":"l-oor345yWqh","outputId":"4f777149-0bc2-4eee-9edc-2f75bccb69fe","execution":{"iopub.status.busy":"2022-11-12T15:24:45.195816Z","iopub.execute_input":"2022-11-12T15:24:45.196222Z","iopub.status.idle":"2022-11-12T15:25:40.494766Z","shell.execute_reply.started":"2022-11-12T15:24:45.196187Z","shell.execute_reply":"2022-11-12T15:25:40.493697Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Ivy Default Cache set to: /root/.ivy2/cache\nThe jars for the packages stored in: /root/.ivy2/jars\n:: loading settings :: url = jar:file:/opt/conda/lib/python3.7/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\ncom.johnsnowlabs.nlp#spark-nlp-gpu_2.11 added as a dependency\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-11ff8408-0705-43cd-aaf2-2a916979fd06;1.0\n\tconfs: [default]\n\tfound com.johnsnowlabs.nlp#spark-nlp-gpu_2.11;2.7.1 in central\n\tfound com.typesafe#config;1.3.0 in central\n\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n\tfound org.apache.hadoop#hadoop-aws;3.2.0 in central\n\tfound com.amazonaws#aws-java-sdk-core;1.11.603 in central\n\tfound commons-logging#commons-logging;1.1.3 in central\n\tfound org.apache.httpcomponents#httpclient;4.5.9 in central\n\tfound org.apache.httpcomponents#httpcore;4.4.11 in central\n\tfound commons-codec#commons-codec;1.11 in central\n\tfound software.amazon.ion#ion-java;1.0.2 in central\n\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.6.7 in central\n\tfound joda-time#joda-time;2.8.1 in central\n\tfound com.amazonaws#aws-java-sdk-s3;1.11.603 in central\n\tfound com.amazonaws#aws-java-sdk-kms;1.11.603 in central\n\tfound com.amazonaws#jmespath-java;1.11.603 in central\n\tfound com.fasterxml.jackson.core#jackson-databind;2.6.7.2 in central\n\tfound com.fasterxml.jackson.core#jackson-annotations;2.6.0 in central\n\tfound com.fasterxml.jackson.core#jackson-core;2.6.7 in central\n\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n\tfound com.google.code.findbugs#annotations;3.0.1 in central\n\tfound net.jcip#jcip-annotations;1.0 in central\n\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n\tfound com.google.code.gson#gson;2.3 in central\n\tfound it.unimi.dsi#fastutil;7.0.12 in central\n\tfound org.projectlombok#lombok;1.16.8 in central\n\tfound org.slf4j#slf4j-api;1.7.21 in central\n\tfound com.navigamez#greex;1.0 in central\n\tfound dk.brics.automaton#automaton;1.11-8 in central\n\tfound org.json4s#json4s-ext_2.11;3.5.3 in central\n\tfound joda-time#joda-time;2.9.5 in central\n\tfound org.joda#joda-convert;1.8.1 in central\n\tfound org.tensorflow#libtensorflow;1.15.0 in central\n\tfound org.tensorflow#libtensorflow_jni_gpu;1.15.0 in central\n\tfound net.sf.trove4j#trove4j;3.0.3 in central\ndownloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp-gpu_2.11/2.7.1/spark-nlp-gpu_2.11-2.7.1.jar ...\n\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp-gpu_2.11;2.7.1!spark-nlp-gpu_2.11.jar (1624ms)\ndownloading https://repo1.maven.org/maven2/com/typesafe/config/1.3.0/config-1.3.0.jar ...\n\t[SUCCESSFUL ] com.typesafe#config;1.3.0!config.jar(bundle) (96ms)\ndownloading https://repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.5.3/rocksdbjni-6.5.3.jar ...\n\t[SUCCESSFUL ] org.rocksdb#rocksdbjni;6.5.3!rocksdbjni.jar (946ms)\ndownloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.2.0/hadoop-aws-3.2.0.jar ...\n\t[SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.2.0!hadoop-aws.jar (97ms)\ndownloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.11.603/aws-java-sdk-core-1.11.603.jar ...\n\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-core;1.11.603!aws-java-sdk-core.jar (102ms)\ndownloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.11.603/aws-java-sdk-s3-1.11.603.jar ...\n\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-s3;1.11.603!aws-java-sdk-s3.jar (102ms)\ndownloading https://repo1.maven.org/maven2/com/github/universal-automata/liblevenshtein/3.0.0/liblevenshtein-3.0.0.jar ...\n\t[SUCCESSFUL ] com.github.universal-automata#liblevenshtein;3.0.0!liblevenshtein.jar (95ms)\ndownloading https://repo1.maven.org/maven2/com/navigamez/greex/1.0/greex-1.0.jar ...\n\t[SUCCESSFUL ] com.navigamez#greex;1.0!greex.jar (103ms)\ndownloading https://repo1.maven.org/maven2/org/json4s/json4s-ext_2.11/3.5.3/json4s-ext_2.11-3.5.3.jar ...\n\t[SUCCESSFUL ] org.json4s#json4s-ext_2.11;3.5.3!json4s-ext_2.11.jar (98ms)\ndownloading https://repo1.maven.org/maven2/org/tensorflow/libtensorflow/1.15.0/libtensorflow-1.15.0.jar ...\n\t[SUCCESSFUL ] org.tensorflow#libtensorflow;1.15.0!libtensorflow.jar (112ms)\ndownloading https://repo1.maven.org/maven2/org/tensorflow/libtensorflow_jni_gpu/1.15.0/libtensorflow_jni_gpu-1.15.0.jar ...\n\t[SUCCESSFUL ] org.tensorflow#libtensorflow_jni_gpu;1.15.0!libtensorflow_jni_gpu.jar (11298ms)\ndownloading https://repo1.maven.org/maven2/net/sf/trove4j/trove4j/3.0.3/trove4j-3.0.3.jar ...\n\t[SUCCESSFUL ] net.sf.trove4j#trove4j;3.0.3!trove4j.jar (112ms)\ndownloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (93ms)\ndownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.9/httpclient-4.5.9.jar ...\n\t[SUCCESSFUL ] org.apache.httpcomponents#httpclient;4.5.9!httpclient.jar (99ms)\ndownloading https://repo1.maven.org/maven2/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar ...\n\t[SUCCESSFUL ] software.amazon.ion#ion-java;1.0.2!ion-java.jar(bundle) (101ms)\ndownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.6.7/jackson-dataformat-cbor-2.6.7.jar ...\n\t[SUCCESSFUL ] com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.6.7!jackson-dataformat-cbor.jar(bundle) (94ms)\ndownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.11/httpcore-4.4.11.jar ...\n\t[SUCCESSFUL ] org.apache.httpcomponents#httpcore;4.4.11!httpcore.jar (97ms)\ndownloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.11/commons-codec-1.11.jar ...\n\t[SUCCESSFUL ] commons-codec#commons-codec;1.11!commons-codec.jar (96ms)\ndownloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-kms/1.11.603/aws-java-sdk-kms-1.11.603.jar ...\n\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-kms;1.11.603!aws-java-sdk-kms.jar (97ms)\ndownloading https://repo1.maven.org/maven2/com/amazonaws/jmespath-java/1.11.603/jmespath-java-1.11.603.jar ...\n\t[SUCCESSFUL ] com.amazonaws#jmespath-java;1.11.603!jmespath-java.jar (94ms)\ndownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.6.7.2/jackson-databind-2.6.7.2.jar ...\n\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-databind;2.6.7.2!jackson-databind.jar(bundle) (105ms)\ndownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.6.0/jackson-annotations-2.6.0.jar ...\n\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-annotations;2.6.0!jackson-annotations.jar(bundle) (96ms)\ndownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.6.7/jackson-core-2.6.7.jar ...\n\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-core;2.6.7!jackson-core.jar(bundle) (99ms)\ndownloading https://repo1.maven.org/maven2/com/google/code/findbugs/annotations/3.0.1/annotations-3.0.1.jar ...\n\t[SUCCESSFUL ] com.google.code.findbugs#annotations;3.0.1!annotations.jar (94ms)\ndownloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java-util/3.0.0-beta-3/protobuf-java-util-3.0.0-beta-3.jar ...\n\t[SUCCESSFUL ] com.google.protobuf#protobuf-java-util;3.0.0-beta-3!protobuf-java-util.jar(bundle) (96ms)\ndownloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.0.0-beta-3/protobuf-java-3.0.0-beta-3.jar ...\n\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.0.0-beta-3!protobuf-java.jar(bundle) (110ms)\ndownloading https://repo1.maven.org/maven2/it/unimi/dsi/fastutil/7.0.12/fastutil-7.0.12.jar ...\n\t[SUCCESSFUL ] it.unimi.dsi#fastutil;7.0.12!fastutil.jar (580ms)\ndownloading https://repo1.maven.org/maven2/org/projectlombok/lombok/1.16.8/lombok-1.16.8.jar ...\n\t[SUCCESSFUL ] org.projectlombok#lombok;1.16.8!lombok.jar (104ms)\ndownloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar ...\n\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.21!slf4j-api.jar (94ms)\ndownloading https://repo1.maven.org/maven2/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar ...\n\t[SUCCESSFUL ] net.jcip#jcip-annotations;1.0!jcip-annotations.jar (94ms)\ndownloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar ...\n\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.1!jsr305.jar (94ms)\ndownloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.3/gson-2.3.jar ...\n\t[SUCCESSFUL ] com.google.code.gson#gson;2.3!gson.jar (95ms)\ndownloading https://repo1.maven.org/maven2/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar ...\n\t[SUCCESSFUL ] dk.brics.automaton#automaton;1.11-8!automaton.jar (95ms)\ndownloading https://repo1.maven.org/maven2/joda-time/joda-time/2.9.5/joda-time-2.9.5.jar ...\n\t[SUCCESSFUL ] joda-time#joda-time;2.9.5!joda-time.jar (99ms)\ndownloading https://repo1.maven.org/maven2/org/joda/joda-convert/1.8.1/joda-convert-1.8.1.jar ...\n\t[SUCCESSFUL ] org.joda#joda-convert;1.8.1!joda-convert.jar (94ms)\n:: resolution report :: resolve 31880ms :: artifacts dl 17538ms\n\t:: modules in use:\n\tcom.amazonaws#aws-java-sdk-core;1.11.603 from central in [default]\n\tcom.amazonaws#aws-java-sdk-kms;1.11.603 from central in [default]\n\tcom.amazonaws#aws-java-sdk-s3;1.11.603 from central in [default]\n\tcom.amazonaws#jmespath-java;1.11.603 from central in [default]\n\tcom.fasterxml.jackson.core#jackson-annotations;2.6.0 from central in [default]\n\tcom.fasterxml.jackson.core#jackson-core;2.6.7 from central in [default]\n\tcom.fasterxml.jackson.core#jackson-databind;2.6.7.2 from central in [default]\n\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.6.7 from central in [default]\n\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n\tcom.google.code.gson#gson;2.3 from central in [default]\n\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n\tcom.johnsnowlabs.nlp#spark-nlp-gpu_2.11;2.7.1 from central in [default]\n\tcom.navigamez#greex;1.0 from central in [default]\n\tcom.typesafe#config;1.3.0 from central in [default]\n\tcommons-codec#commons-codec;1.11 from central in [default]\n\tcommons-logging#commons-logging;1.1.3 from central in [default]\n\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n\tjoda-time#joda-time;2.9.5 from central in [default]\n\tnet.jcip#jcip-annotations;1.0 from central in [default]\n\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n\torg.apache.hadoop#hadoop-aws;3.2.0 from central in [default]\n\torg.apache.httpcomponents#httpclient;4.5.9 from central in [default]\n\torg.apache.httpcomponents#httpcore;4.4.11 from central in [default]\n\torg.joda#joda-convert;1.8.1 from central in [default]\n\torg.json4s#json4s-ext_2.11;3.5.3 from central in [default]\n\torg.projectlombok#lombok;1.16.8 from central in [default]\n\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n\torg.tensorflow#libtensorflow;1.15.0 from central in [default]\n\torg.tensorflow#libtensorflow_jni_gpu;1.15.0 from central in [default]\n\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n\t:: evicted modules:\n\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n\tjoda-time#joda-time;2.8.1 by [joda-time#joda-time;2.9.5] in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   37  |   36  |   36  |   2   ||   35  |   35  |\n\t---------------------------------------------------------------------\n\n:: problems summary ::\n:::: ERRORS\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/hadoop/hadoop-main/3.2.0/hadoop-main-3.2.0.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/hadoop/hadoop-project/3.2.0/hadoop-project-3.2.0.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/amazonaws/aws-java-sdk-pom/1.11.603/aws-java-sdk-pom-1.11.603.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/apache/13/apache-13.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/commons/commons-parent/28/commons-parent-28.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/apache/21/apache-21.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/httpcomponents/httpcomponents-parent/11/httpcomponents-parent-11.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/httpcomponents/httpcomponents-client/4.5.9/httpcomponents-client-4.5.9.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/httpcomponents/httpcomponents-core/4.4.11/httpcomponents-core-4.4.11.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/apache/18/apache-18.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/apache/commons/commons-parent/42/commons-parent-42.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/fasterxml/oss-parent/24/oss-parent-24.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/fasterxml/jackson/jackson-parent/2.6.2/jackson-parent-2.6.2.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/fasterxml/oss-parent/23/oss-parent-23.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/fasterxml/jackson/jackson-parent/2.6.1/jackson-parent-2.6.1.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/sonatype/oss/oss-parent/7/oss-parent-7.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0-javadoc.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/google/google/1/google-1.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/google/protobuf/protobuf-parent/3.0.0-beta-3/protobuf-parent-3.0.0-beta-3.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/google/protobuf/protobuf-java-util/3.0.0-beta-3/protobuf-java-util-3.0.0-beta-3-sources.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/google/protobuf/protobuf-java-util/3.0.0-beta-3/protobuf-java-util-3.0.0-beta-3-src.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/google/protobuf/protobuf-java-util/3.0.0-beta-3/protobuf-java-util-3.0.0-beta-3-javadoc.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/google/protobuf/protobuf-java/3.0.0-beta-3/protobuf-java-3.0.0-beta-3-sources.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/google/protobuf/protobuf-java/3.0.0-beta-3/protobuf-java-3.0.0-beta-3-src.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/google/protobuf/protobuf-java/3.0.0-beta-3/protobuf-java-3.0.0-beta-3-javadoc.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/sonatype/oss/oss-parent/9/oss-parent-9.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/slf4j/slf4j-parent/1.7.21/slf4j-parent-1.7.21.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/tensorflow/parentpom/1.15.0/parentpom-1.15.0.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/tensorflow/libtensorflow_jni_gpu/1.15.0/libtensorflow_jni_gpu-1.15.0-sources.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/tensorflow/libtensorflow_jni_gpu/1.15.0/libtensorflow_jni_gpu-1.15.0-src.jar\n\n\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/org/tensorflow/libtensorflow_jni_gpu/1.15.0/libtensorflow_jni_gpu-1.15.0-javadoc.jar\n\n\n:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n:: retrieving :: org.apache.spark#spark-submit-parent-11ff8408-0705-43cd-aaf2-2a916979fd06\n\tconfs: [default]\n\t35 artifacts copied, 0 already retrieved (465296kB/518ms)\n22/11/12 15:25:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"Spark NLP version 2.7.1\nApache Spark version: 2.4.4\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7f41f44d8cd0>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://3ea27c42d80c:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Spark NLP</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"cell_type":"code","source":"# df = pd.read_csv('../input/twitter-class-balanced/balanced_data.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T15:26:00.386391Z","iopub.execute_input":"2022-11-12T15:26:00.386804Z","iopub.status.idle":"2022-11-12T15:26:00.395276Z","shell.execute_reply.started":"2022-11-12T15:26:00.386768Z","shell.execute_reply":"2022-11-12T15:26:00.391108Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# df = df.drop(columns='Unnamed: 0',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T15:26:01.006356Z","iopub.execute_input":"2022-11-12T15:26:01.007283Z","iopub.status.idle":"2022-11-12T15:26:01.694480Z","shell.execute_reply.started":"2022-11-12T15:26:01.007232Z","shell.execute_reply":"2022-11-12T15:26:01.693272Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X = df['text']\n# y = df['class']\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-12T15:26:02.908656Z","iopub.execute_input":"2022-11-12T15:26:02.909018Z","iopub.status.idle":"2022-11-12T15:26:02.913674Z","shell.execute_reply.started":"2022-11-12T15:26:02.908987Z","shell.execute_reply":"2022-11-12T15:26:02.912575Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# train = list(zip(X_train, y_train))\n# test = list(zip(X_test,y_test))\n# df_train = pd.DataFrame(data = train,columns = ['description','category'])\n# df_test = pd.DataFrame(data = test)\n# df_train.to_csv('train_twitter')\n# df_test.to_csv('test_twitter')","metadata":{"execution":{"iopub.status.busy":"2022-11-12T15:26:04.300963Z","iopub.execute_input":"2022-11-12T15:26:04.301322Z","iopub.status.idle":"2022-11-12T15:26:04.306433Z","shell.execute_reply.started":"2022-11-12T15:26:04.301290Z","shell.execute_reply":"2022-11-12T15:26:04.305281Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# ! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n# ! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgdtDVmxyZRZ","outputId":"03516dfb-c67e-47e7-8393-b7b5970068da","execution":{"iopub.status.busy":"2022-11-12T15:26:05.747043Z","iopub.execute_input":"2022-11-12T15:26:05.747409Z","iopub.status.idle":"2022-11-12T15:26:05.752250Z","shell.execute_reply.started":"2022-11-12T15:26:05.747377Z","shell.execute_reply":"2022-11-12T15:26:05.751065Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df = spark.read \\\n      .option(\"header\", True) \\\n      .csv(\"../input/twitter-separated/train_twitter.csv\")\ndf.show(truncate=50)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IzpG9u0jz0xT","outputId":"7b41b818-24ff-4c85-afb6-0dd059b40c45","execution":{"iopub.status.busy":"2022-11-12T15:26:12.519146Z","iopub.execute_input":"2022-11-12T15:26:12.519520Z","iopub.status.idle":"2022-11-12T15:26:20.716713Z","shell.execute_reply.started":"2022-11-12T15:26:12.519488Z","shell.execute_reply":"2022-11-12T15:26:20.715693Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+--------------------------------------------------+--------+\n|                                       description|category|\n+--------------------------------------------------+--------+\n|she say she like me cuz ima real man . . . . . ...|       5|\n|babygirl as jiggling dropping it low doing the ...|       1|\n|my only talent is being able to do both the uwu...|       2|\n|sobie ade buat postage rini pat pat jom all rea...|       2|\n|i should make a video on that can it be top num...|       1|\n|you can really pull off both cutesy and sexy huh ?|       2|\n|yeah i m still trying to understand what the he...|       6|\n|politics ha no place in professional sports . p...|       3|\n|i would have if i wasn t spoiled by it s ending...|       4|\n|it s always great to see the bivouac . it does ...|       5|\n|bruh when i don t have the kid i m up so early ...|       4|\n|this is so real tho i ll rlly be dying doing ha...|       7|\n|infact i just noticed the views k am like who a...|       7|\n|just set my hair appointment and the soonest da...|       1|\n|taking my mum to the hospital for her nd vaccin...|       7|\n|is it normal to release the sampler on d number...|       4|\n|thai tea is my always go to ! but i love banana...|       2|\n|just switched to mongraal sen and it feel so go...|       1|\n|it s like i want to talk to people about the sh...|       1|\n|don t ever try to speak fear into my plan think...|       5|\n+--------------------------------------------------+--------+\nonly showing top 20 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from pyspark.sql.functions import col\ndf.groupBy(\"category\") \\\n    .count() \\\n    .orderBy(col(\"count\").desc()) \\\n    .show()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLvsrmah6r0K","outputId":"0dc88c17-16eb-4c97-d4a8-ea58bfcc217e","execution":{"iopub.status.busy":"2022-11-12T15:26:43.776746Z","iopub.execute_input":"2022-11-12T15:26:43.777298Z","iopub.status.idle":"2022-11-12T15:26:48.828885Z","shell.execute_reply.started":"2022-11-12T15:26:43.777255Z","shell.execute_reply":"2022-11-12T15:26:48.827874Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"+--------+-----+\n|category|count|\n+--------+-----+\n|       4|17343|\n|       1|17315|\n|       5|17294|\n|       7|17272|\n|       3|17240|\n|       6|17208|\n|       2|17184|\n+--------+-----+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"(train_df, val_df) = df.randomSplit([0.7, 0.3], seed = 8)\nprint(\"Training Dataset Count: \" + str(train_df.count()))\nprint(\"Validation Dataset Count: \" + str(val_df.count()))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"640z0f8u6138","outputId":"a93d9e5b-973e-45f5-fb11-ec0129774819","execution":{"iopub.status.busy":"2022-11-12T15:26:56.292360Z","iopub.execute_input":"2022-11-12T15:26:56.292743Z","iopub.status.idle":"2022-11-12T15:26:58.828807Z","shell.execute_reply.started":"2022-11-12T15:26:56.292708Z","shell.execute_reply":"2022-11-12T15:26:58.827679Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Training Dataset Count: 84671\nValidation Dataset Count: 36185\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# actual content is inside description column\ndocument = DocumentAssembler() \\\n.setInputCol(\"description\") \\\n.setOutputCol(\"document\") \\\n.setCleanupMode(\"shrink\")\n\nbert = BertSentenceEmbeddings.pretrained('sent_bert_base_cased') \\\n.setInputCols(\"document\") \\\n.setOutputCol(\"bert_sentence_embeddings\") \\\n.setLazyAnnotator(False)\n\n# the classes/labels/categories are in category column\nclassifierdl = ClassifierDLApproach()\\\n.setInputCols([\"bert_sentence_embeddings\"])\\\n.setOutputCol(\"class\")\\\n.setLabelColumn(\"category\")\\\n.setMaxEpochs(4)\\\n.setLr(0.001)\\\n.setBatchSize(64)\\\n.setEnableOutputLogs(True)\n#.setOutputLogsPath('logs')\n\npipeline = Pipeline(\n    stages = [\n        document,\n        bert,\n        classifierdl\n    ])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0X-he2WZ66-K","outputId":"acfc1cb8-6e64-4bc5-a616-03e8763aa013","execution":{"iopub.status.busy":"2022-11-12T15:27:22.750039Z","iopub.execute_input":"2022-11-12T15:27:22.750422Z","iopub.status.idle":"2022-11-12T15:27:53.358863Z","shell.execute_reply.started":"2022-11-12T15:27:22.750389Z","shell.execute_reply":"2022-11-12T15:27:53.357802Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"sent_bert_base_cased download started this may take some time.\n","output_type":"stream"},{"name":"stderr","text":"22/11/12 15:27:23 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:23 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n","output_type":"stream"},{"name":"stdout","text":"Approximate size to download 389.1 MB\n[ | ]","output_type":"stream"},{"name":"stderr","text":"22/11/12 15:27:25 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:25 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:25 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:25 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:25 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:25 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n","output_type":"stream"},{"name":"stdout","text":"sent_bert_base_cased download started this may take some time.\n","output_type":"stream"},{"name":"stderr","text":"22/11/12 15:27:26 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:26 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n","output_type":"stream"},{"name":"stdout","text":"Approximate size to download 389.1 MB\n","output_type":"stream"},{"name":"stderr","text":"22/11/12 15:27:26 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:26 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:27 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n22/11/12 15:27:27 WARN ApacheUtils: NoSuchMethodError was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information\n","output_type":"stream"},{"name":"stdout","text":"[ — ]Download done! Loading the resource.\n[ / ]","output_type":"stream"},{"name":"stderr","text":"2022-11-12 15:27:49.942845: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n2022-11-12 15:27:49.989184: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz\n2022-11-12 15:27:49.990949: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb73a58ac30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2022-11-12 15:27:49.990991: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2022-11-12 15:27:49.995484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n2022-11-12 15:27:50.084668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-12 15:27:50.085955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:00:04.0\n2022-11-12 15:27:50.086631: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:27:50.087208: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:27:50.087733: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:27:50.088222: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:27:50.088703: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:27:50.089169: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:27:50.089654: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:27:50.089857: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n2022-11-12 15:27:50.434225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n2022-11-12 15:27:50.435935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n2022-11-12 15:27:50.437308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","output_type":"stream"},{"name":"stdout","text":"[OK!]\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\npipelineModel = pipeline.fit(train_df)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmNZXUcO7LC4","outputId":"e857445e-063f-41e2-b538-5b72d960971a","execution":{"iopub.status.busy":"2022-11-12T15:28:01.092719Z","iopub.execute_input":"2022-11-12T15:28:01.093121Z","iopub.status.idle":"2022-11-12T17:30:48.514848Z","shell.execute_reply.started":"2022-11-12T15:28:01.093087Z","shell.execute_reply":"2022-11-12T17:30:48.513656Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2022-11-12 15:28:04.265537: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /tmp/289531f5715f_classifier_dl4209532244932976113\n2022-11-12 15:28:04.340762: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n2022-11-12 15:28:04.471925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-12 15:28:04.472987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:00:04.0\n2022-11-12 15:28:04.473208: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:28:04.473341: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:28:04.473458: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:28:04.473572: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:28:04.474367: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:28:04.475137: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:28:04.475772: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 15:28:04.475906: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n2022-11-12 15:28:04.475942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n2022-11-12 15:28:04.475957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n2022-11-12 15:28:04.475972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n2022-11-12 15:28:04.953997: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.\n2022-11-12 15:28:06.646799: I tensorflow/cc/saved_model/loader.cc:151] Running initialization op on SavedModel bundle at path: /tmp/289531f5715f_classifier_dl4209532244932976113\n2022-11-12 15:28:07.116913: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 2851378 microseconds.\n                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Training started - epochs: 4 - learning_rate: 0.001 - batch_size: 64 - training_examples: 84671 - classes: 7\nEpoch 1/4 - 19.74s - loss: 2463.582 - acc: 0.2742579 - batches: 1323\nEpoch 2/4 - 17.98s - loss: 2431.7117 - acc: 0.2997752 - batches: 1323\nEpoch 3/4 - 18.62s - loss: 2424.0945 - acc: 0.3070322 - batches: 1323\nEpoch 4/4 - 17.95s - loss: 2419.5562 - acc: 0.31063688 - batches: 1323\nCPU times: user 1.39 s, sys: 223 ms, total: 1.61 s\nWall time: 2h 2min 47s\n","output_type":"stream"}]},{"cell_type":"code","source":"# get the predictions on validation Set\n\npreds = pipelineModel.transform(val_df)","metadata":{"id":"A8JPUtPO7NzY","execution":{"iopub.status.busy":"2022-11-12T17:30:48.516767Z","iopub.execute_input":"2022-11-12T17:30:48.517106Z","iopub.status.idle":"2022-11-12T17:30:48.715986Z","shell.execute_reply.started":"2022-11-12T17:30:48.517071Z","shell.execute_reply":"2022-11-12T17:30:48.714669Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"preds.select('description','category',\"class.result\").show(10, truncate=100)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjJFen8q7O83","outputId":"2dd3218d-5541-438e-e51a-486b51f80792","execution":{"iopub.status.busy":"2022-11-12T17:30:48.717414Z","iopub.execute_input":"2022-11-12T17:30:48.717768Z","iopub.status.idle":"2022-11-12T17:30:53.556927Z","shell.execute_reply.started":"2022-11-12T17:30:48.717735Z","shell.execute_reply":"2022-11-12T17:30:53.554908Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"[Stage 14:>                                                         (0 + 1) / 1]2022-11-12 17:30:49.964595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-12 17:30:49.965651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\npciBusID: 0000:00:04.0\n2022-11-12 17:30:49.965871: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 17:30:49.966001: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 17:30:49.966116: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 17:30:49.966226: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 17:30:49.966337: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 17:30:49.966456: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 17:30:49.966568: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-11-12 17:30:49.966591: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n2022-11-12 17:30:49.966636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n2022-11-12 17:30:49.966651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n2022-11-12 17:30:49.966663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","output_type":"stream"},{"name":"stdout","text":"+---------------------------------------------------------------------------------------------------+--------+------+\n|                                                                                        description|category|result|\n+---------------------------------------------------------------------------------------------------+--------+------+\n|                              ! ! ! ! cool cool ! ! ! i will keep u posted when i start doing stuff|       5|   [2]|\n|                                 ! ! ! ! the shiloh person omg ! ! i am bad at linear thought sorry|       4|   [4]|\n|                                        ! ! ! ! they are the only reason i even want another season|       4|   [3]|\n|! ! happy bday joanne i hope that you had a wonderful day and you were able to enjoy yourself ! ! !|       2|   [2]|\n|                                        ! ! oops . it ha to be panpsychism made it out of my silo .|       6|   [7]|\n|                                          ! ! yes ive been calling you since day number ikon get it|       2|   [2]|\n|                             ! great song and great video ! thank you so much for sharing it with u|       2|   [2]|\n|                                      ! man up and do something ! we re not a third world country !|       3|   [3]|\n|                           ! ut ! d gang sab ke sab ! whole m . v . a minister involved in ssr case|       5|   [7]|\n|       . . . . . . . . . . . . . . . . i also have been known to get my nail done in time of duress|       5|   [7]|\n+---------------------------------------------------------------------------------------------------+--------+------+\nonly showing top 10 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"preds_df = preds.select('description','category',\"class.result\").toPandas()\n\n# The result is an array since in Spark NLP you can have multiple sentences.\n# Let's explode the array and get the item(s) inside of result column out\npreds_df['result'] = preds_df['result'].apply(lambda x : x[0])","metadata":{"id":"MlduuxDV7Vjq","execution":{"iopub.status.busy":"2022-11-12T17:30:53.559110Z","iopub.execute_input":"2022-11-12T17:30:53.559431Z","iopub.status.idle":"2022-11-12T18:22:41.804400Z","shell.execute_reply.started":"2022-11-12T17:30:53.559403Z","shell.execute_reply":"2022-11-12T18:22:41.803431Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"preds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-12T18:29:50.551666Z","iopub.execute_input":"2022-11-12T18:29:50.552076Z","iopub.status.idle":"2022-11-12T18:29:50.579229Z","shell.execute_reply.started":"2022-11-12T18:29:50.552042Z","shell.execute_reply":"2022-11-12T18:29:50.578369Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                             description category result\n0      ! ! ! ! cool cool ! ! ! i will keep u posted w...        5      2\n1      ! ! ! ! the shiloh person omg ! ! i am bad at ...        4      4\n2      ! ! ! ! they are the only reason i even want a...        4      3\n3      ! ! happy bday joanne i hope that you had a wo...        2      2\n4      ! ! oops . it ha to be panpsychism made it out...        6      7\n...                                                  ...      ...    ...\n36180  zero wish lmao . i spent em all but i can get ...        6      3\n36181  zimbabwe is a good example of a bad example . ...        7      5\n36182  zoa is so pretty idk but she reminds of tzuyu ...        4      2\n36183  zombie llama over here have a great rest of yo...        2      2\n36184  zootopia wa fun to watch they still dont admit...        3      5\n\n[36185 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>description</th>\n      <th>category</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>! ! ! ! cool cool ! ! ! i will keep u posted w...</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>! ! ! ! the shiloh person omg ! ! i am bad at ...</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>! ! ! ! they are the only reason i even want a...</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>! ! happy bday joanne i hope that you had a wo...</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>! ! oops . it ha to be panpsychism made it out...</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36180</th>\n      <td>zero wish lmao . i spent em all but i can get ...</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>36181</th>\n      <td>zimbabwe is a good example of a bad example . ...</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>36182</th>\n      <td>zoa is so pretty idk but she reminds of tzuyu ...</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>36183</th>\n      <td>zombie llama over here have a great rest of yo...</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>36184</th>\n      <td>zootopia wa fun to watch they still dont admit...</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>36185 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# We are going to use sklearn to evalute the results on test dataset\nfrom sklearn.metrics import classification_report\n\nprint (classification_report(preds_df['result'], preds_df['category']))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iC_DalJs7j3A","outputId":"bb811b2c-6be6-417f-8fc8-129cec70e1a2","execution":{"iopub.status.busy":"2022-11-12T18:22:41.805632Z","iopub.execute_input":"2022-11-12T18:22:41.806002Z","iopub.status.idle":"2022-11-12T18:22:43.172131Z","shell.execute_reply.started":"2022-11-12T18:22:41.805969Z","shell.execute_reply":"2022-11-12T18:22:43.171053Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           1       0.13      0.23      0.17      2873\n           2       0.55      0.45      0.50      6364\n           3       0.48      0.28      0.35      8920\n           4       0.33      0.28      0.30      5943\n           5       0.36      0.31      0.33      5968\n           6       0.00      0.57      0.00         7\n           7       0.29      0.25      0.27      6110\n\n    accuracy                           0.31     36185\n   macro avg       0.31      0.34      0.27     36185\nweighted avg       0.39      0.31      0.34     36185\n\n","output_type":"stream"}]},{"cell_type":"code","source":"pipelineModel.save(\"./spark-NLP-bert\")","metadata":{"execution":{"iopub.status.busy":"2022-11-12T18:31:56.534277Z","iopub.execute_input":"2022-11-12T18:31:56.534722Z","iopub.status.idle":"2022-11-12T18:35:31.453458Z","shell.execute_reply.started":"2022-11-12T18:31:56.534682Z","shell.execute_reply":"2022-11-12T18:35:31.452382Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"22/11/12 18:31:56 WARN TaskSetManager: Stage 25 contains a task of very large size (209 KB). The maximum recommended task size is 100 KB.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}